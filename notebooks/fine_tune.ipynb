{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets[audio]==3.0.1\n",
    "%pip install mcap==1.2.1\n",
    "%pip install torch\n",
    "%pip install torchaudio\n",
    "%pip install transformers[torch]==4.46.2\n",
    "%pip install nstrumenta==0.1.3\n",
    "%pip install evaluate\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from nstrumenta import NstrumentaClient\n",
    "\n",
    "# Store the initial working directory\n",
    "initial_cwd = os.getcwd()\n",
    "\n",
    "# use colab user data or getenv\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"NSTRUMENTA_API_KEY\"] = userdata.get(\"NSTRUMENTA_API_KEY\")\n",
    "\n",
    "nst_client = NstrumentaClient(os.getenv(\"NSTRUMENTA_API_KEY\"))\n",
    "\n",
    "print(nst_client.get_project())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reset the cwd to the initial directory\n",
    "def reset_cwd():\n",
    "    os.chdir(initial_cwd)\n",
    "    print(f\"Current working directory reset to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "model_id = 'DCCB74'  # uuid.uuid4().hex.upper()[:6]\n",
    "\n",
    "working_folder = f\"./temp/{model_id}\"\n",
    "\n",
    "# set working folder to the project root\n",
    "reset_cwd()\n",
    "# change to the working folder\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "os.chdir(working_folder)\n",
    "\n",
    "\n",
    "# print the current working directory\n",
    "print(f\"current working directory: {os.getcwd()}\")\n",
    "\n",
    "\n",
    "def download_if_not_exists(file, dest=None, extract=False):\n",
    "    dest = dest if dest else file\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"downloading {file} to {dest}.\")\n",
    "        nst_client.download(file, dest)\n",
    "        if extract:\n",
    "            with tarfile.open(dest, \"r:gz\") as tar:\n",
    "                tar.extractall()\n",
    "\n",
    "    else:\n",
    "        print(f\"{dest} exists.\")\n",
    "\n",
    "download_if_not_exists('mcap_utilities.py')\n",
    "\n",
    "import mcap_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ASTFeatureExtractor\n",
    "\n",
    "# we define which pretrained model we want to use and instantiate a feature extractor\n",
    "pretrained_model = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pairs = []\n",
    "logs = [\n",
    "    \"Sensor_Log_2023-11-08_07_36_21\",\n",
    "    \"Sensor_Log_2023-11-08_08_25_49\",\n",
    "    \"Sensor_Log_2023-12-07_10_20_28\",\n",
    "    \"Sensor_Log_2023-11-08_09_05_43\",\n",
    "]\n",
    "for log_prefix in logs:\n",
    "    # download the input file and label file\n",
    "    input_file = f\"{log_prefix}.mcap\"\n",
    "    label_file = f\"{log_prefix}.labels.json\"\n",
    "    spectrogram_mcap_file = f\"{log_prefix}.spectrogram.mcap\"\n",
    "    file_pairs.append([spectrogram_mcap_file, label_file])\n",
    "    download_if_not_exists(input_file)\n",
    "    download_if_not_exists(label_file)\n",
    "\n",
    "    def create_spectrogram_if_not_exists(input_file, spectrogram_mcap_file):\n",
    "        if not os.path.exists(spectrogram_mcap_file):\n",
    "            mcap_utilities.spectrogram_from_timeseries(\n",
    "                input_file=input_file,\n",
    "                spectrogram_mcap_file=spectrogram_mcap_file,\n",
    "                feature_extractor=feature_extractor,\n",
    "            )\n",
    "            nst_client.upload(\n",
    "                spectrogram_mcap_file,\n",
    "                f\"{model_id}/{spectrogram_mcap_file}\",\n",
    "                overwrite=True,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{spectrogram_mcap_file} exists.\")\n",
    "\n",
    "    create_spectrogram_if_not_exists(input_file, spectrogram_mcap_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset from the file pairs [spectrogram_file, label_file]\n",
    "dataset = mcap_utilities.create_dataset(\n",
    "    file_pairs=file_pairs,\n",
    "    use_unlabeled_sections=True,\n",
    "    unlabeled_section_label=\"low\",\n",
    "    aggregate_labels=True,\n",
    "    aggregate_label_dict={\n",
    "        \"10_kV\": \"medium\",\n",
    "        \"20_kV\": \"medium\",\n",
    "        \"110_kV\": \"high\",\n",
    "        \"130_kV\": \"high\",\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset.save_to_disk(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ASTConfig, ASTForAudioClassification\n",
    "\n",
    "# Load configuration from the pretrained model\n",
    "config = ASTConfig.from_pretrained(pretrained_model)\n",
    "\n",
    "# Access the ClassLabel feature for the labels\n",
    "label_feature = dataset.features[\"labels\"]\n",
    "\n",
    "# Get the label names\n",
    "label_names = label_feature.names\n",
    "\n",
    "print(\"Label names:\", label_names)\n",
    "\n",
    "config.num_labels = len(label_names)\n",
    "config.label2id = {label: i for i, label in enumerate(label_names)}\n",
    "config.id2label = {i: label for label, i in config.label2id.items()}\n",
    "\n",
    "\n",
    "# split training data\n",
    "if \"test\" not in dataset:\n",
    "    dataset = dataset.train_test_split(\n",
    "        test_size=0.2, shuffle=True, seed=0, stratify_by_column=\"labels\"\n",
    "    )\n",
    "\n",
    "# Initialize the model with the updated configuration\n",
    "model = ASTForAudioClassification.from_pretrained(\n",
    "    pretrained_model, config=config, ignore_mismatched_sizes=True\n",
    ")\n",
    "model.init_weights()\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Configure training run with TrainingArguments class\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"runs\",\n",
    "    logging_dir=\"logs\",\n",
    "    report_to=\"tensorboard\",\n",
    "    learning_rate=5e-5,  # Learning rate\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=5,  # Number of epochs\n",
    "    per_device_train_batch_size=8,  # Batch size per device\n",
    "    eval_strategy=\"epoch\",  # Evaluation strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "AVERAGE = \"macro\" if config.num_labels > 2 else \"binary\"\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metrics = accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "    metrics.update(\n",
    "        precision.compute(\n",
    "            predictions=predictions, references=eval_pred.label_ids, average=AVERAGE\n",
    "        )\n",
    "    )\n",
    "    metrics.update(\n",
    "        recall.compute(\n",
    "            predictions=predictions, references=eval_pred.label_ids, average=AVERAGE\n",
    "        )\n",
    "    )\n",
    "    metrics.update(\n",
    "        f1.compute(\n",
    "            predictions=predictions, references=eval_pred.label_ids, average=AVERAGE\n",
    "        )\n",
    "    )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "# Setup the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,  # Use the metrics function from above\n",
    ")\n",
    "\n",
    "# print command to start tensorboard in another terminal\n",
    "print(f\"tensorboard --logdir={training_args.logging_dir}\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# save trained model\n",
    "trainer.save_model(\"model\")\n",
    "\n",
    "# package model folder up as tarball\n",
    "model_tar_filename = f\"{model_id}.model.tar.gz\"\n",
    "print(f\"packaging model folder into {model_tar_filename}\")\n",
    "with tarfile.open(model_tar_filename, \"w:gz\") as tar:\n",
    "    tar.add(\"model\", arcname=os.path.basename(\"model\"))\n",
    "\n",
    "# upload model to nstrumenta\n",
    "print(f\"uploading {model_tar_filename} to nstrumenta.\")\n",
    "nst_client.upload(model_tar_filename, f\"{model_tar_filename}\", overwrite=True)\n",
    "\n",
    "# run inference on test set\n",
    "predictions = trainer.predict(dataset[\"test\"])\n",
    "print(predictions)\n",
    "\n",
    "# print some training metrics\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
