{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Add src directory to path for modular imports\n",
    "script_dir = os.path.dirname(os.path.abspath(''))\n",
    "src_dir = os.path.abspath(os.path.join(script_dir, \"src\"))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "print(\"ğŸ”¬ Synthetic Data Explorer & Generator\")\n",
    "print(\"=====================================\")\n",
    "print(\"This notebook demonstrates the complete synthetic data pipeline\")\n",
    "print(\"for magnetic distortion classification.\\n\")\n",
    "\n",
    "# Try to use new modular imports\n",
    "try:\n",
    "    from mcap_utils import read_synthetic_sensor_data, plot_synthetic_sensor_data, extract_imu_windows\n",
    "    from synthetic import SyntheticDataGenerator\n",
    "    print(\"âœ… Modular architecture loaded successfully\")\n",
    "    modular_available = True\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Modular imports failed: {e}\")\n",
    "    print(\"Trying legacy imports...\")\n",
    "    try:\n",
    "        import mcap_utilities\n",
    "        from synthetic import SyntheticDataGenerator  # This should still work\n",
    "        read_synthetic_sensor_data = mcap_utilities.read_synthetic_sensor_data\n",
    "        plot_synthetic_sensor_data = mcap_utilities.plot_synthetic_sensor_data\n",
    "        extract_imu_windows = mcap_utilities.extract_imu_windows\n",
    "        print(\"âœ… Legacy imports successful\")\n",
    "        modular_available = False\n",
    "    except ImportError as e2:\n",
    "        print(f\"âŒ All imports failed: {e2}\")\n",
    "        print(\"Please check your environment setup\")\n",
    "        modular_available = False\n",
    "\n",
    "if modular_available:\n",
    "    # Demo 1: Generate Synthetic Data Live\n",
    "    print(\"\\nğŸ§ª Demo 1: Live Synthetic Data Generation\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    try:\n",
    "        generator = SyntheticDataGenerator()\n",
    "        print(\"âœ… SyntheticDataGenerator initialized\")\n",
    "        \n",
    "        # Create a simple demonstration plan\n",
    "        demo_plan = {\n",
    "            \"initialization\": {\n",
    "                \"pose\": {\n",
    "                    \"origin\": {\"lat\": 38.446, \"lng\": -122.687, \"height\": 0.0},\n",
    "                    \"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0},\n",
    "                    \"rotation\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}\n",
    "                },\n",
    "                \"start_time_ns\": 0,\n",
    "                \"sample_rate\": 50,  # Lower sample rate for demo\n",
    "                \"mag\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[0.00053, 0.0, 0.0], [0.0, 0.00053, 0.0], [0.0, 0.0, 0.00053]]}},\n",
    "                \"acc\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}},\n",
    "                \"gyro\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}}\n",
    "            },\n",
    "            \"segments\": [\n",
    "                {\n",
    "                    \"name\": \"demo_none\",\n",
    "                    \"duration_s\": 10.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 30.0, \"pitch\": 0.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": 0.0,\n",
    "                    \"mag_distortion\": {\"level\": \"none\"}\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"demo_high\",\n",
    "                    \"duration_s\": 10.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 0.0, \"pitch\": 30.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": 2.5,\n",
    "                    \"mag_distortion\": {\"level\": \"high\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Generate demo data\n",
    "        demo_file = \"demo_synthetic_data.mcap\"\n",
    "        demo_labels = \"demo_synthetic_data.labels.json\"\n",
    "        \n",
    "        print(\"\udd04 Generating 20 seconds of demo data...\")\n",
    "        generator.generate(plan_data=demo_plan, output_file=demo_file, verbose=False)\n",
    "        generator.generate_labels(demo_plan, demo_labels)\n",
    "        \n",
    "        if os.path.exists(demo_file):\n",
    "            file_size = os.path.getsize(demo_file)\n",
    "            print(f\"âœ… Generated {demo_file} ({file_size:,} bytes)\")\n",
    "            \n",
    "            # Read and analyze the generated data\n",
    "            print(\"\\nğŸ“Š Analyzing Generated Data...\")\n",
    "            data = read_synthetic_sensor_data(demo_file)\n",
    "            \n",
    "            print(f\"ğŸ“‹ Available channels ({len(data)}):\")\n",
    "            for channel, channel_data in data.items():\n",
    "                if len(channel_data) > 0:\n",
    "                    timestamps = [item[0] for item in channel_data[:5]]  # First 5 timestamps\n",
    "                    print(f\"  ğŸ“ˆ {channel}: {len(channel_data)} samples\")\n",
    "                    if len(channel_data) > 0:\n",
    "                        sample_timestamp, sample_values = channel_data[0]\n",
    "                        print(f\"      Sample: t={sample_timestamp/1e9:.3f}s, values={sample_values}\")\n",
    "            \n",
    "            # Analyze labels\n",
    "            print(f\"\\nğŸ·ï¸  Analyzing Labels...\")\n",
    "            with open(demo_labels, 'r') as f:\n",
    "                labels_data = json.load(f)\n",
    "                events = labels_data.get('events', [])\n",
    "                print(f\"ğŸ“‹ Found {len(events)} labeled events:\")\n",
    "                for i, event in enumerate(events):\n",
    "                    name = event.get('metadata', {}).get('mag_distortion', 'unknown')\n",
    "                    start_time = event['startTime']['sec']\n",
    "                    end_time = event['endTime']['sec']\n",
    "                    duration = end_time - start_time\n",
    "                    print(f\"  {i+1}. {name} distortion: {start_time}s - {end_time}s ({duration}s)\")\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ Failed to generate demo data\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in synthetic data generation: {e}\")\n",
    "    \n",
    "    # Demo 2: Data Analysis and Visualization\n",
    "    print(f\"\\nğŸ“Š Demo 2: Data Analysis & Visualization\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    if 'demo_file' in locals() and os.path.exists(demo_file):\n",
    "        try:\n",
    "            # Extract windows for ML\n",
    "            print(\"ğŸ”„ Extracting windows for machine learning...\")\n",
    "            windows = extract_imu_windows(demo_file, window_size_ns=2e9, channels=['mag_truth', 'acc_truth', 'gyro_truth'])\n",
    "            \n",
    "            if len(windows) > 0:\n",
    "                print(f\"âœ… Extracted {len(windows)} windows\")\n",
    "                print(f\"   Window shape: {windows[0].shape}\")\n",
    "                print(f\"   Data type: {windows[0].dtype}\")\n",
    "                \n",
    "                # Show some statistics\n",
    "                print(f\"\\nğŸ“ˆ Window Statistics:\")\n",
    "                all_data = np.concatenate(windows, axis=0)\n",
    "                print(f\"   Combined shape: {all_data.shape}\")\n",
    "                print(f\"   Data range: [{np.min(all_data):.3f}, {np.max(all_data):.3f}]\")\n",
    "                print(f\"   Mean: {np.mean(all_data):.3f}\")\n",
    "                print(f\"   Std: {np.std(all_data):.3f}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ No windows extracted\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not extract windows: {e}\")\n",
    "    \n",
    "    # Demo 3: Integration with ML Pipeline\n",
    "    print(f\"\\nğŸ¤– Demo 3: Machine Learning Integration\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    try:\n",
    "        from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "        \n",
    "        # Load a pretrained model for demonstration\n",
    "        print(\"ğŸ”„ Loading pretrained Audio Spectrogram Transformer...\")\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        \n",
    "        print(\"âœ… Loaded pretrained AST model\")\n",
    "        print(f\"   ğŸ“Š Model classes: {model.config.num_labels}\")\n",
    "        print(f\"   ğŸ·ï¸  Sample classes: {list(model.config.id2label.values())[:5]}...\")\n",
    "        \n",
    "        # Show how to create spectrograms\n",
    "        if 'demo_file' in locals() and os.path.exists(demo_file):\n",
    "            try:\n",
    "                from mcap_utils import spectrogram_from_timeseries\n",
    "                spectrogram_file = \"demo_synthetic_data.spectrogram.mcap\"\n",
    "                \n",
    "                print(f\"ğŸ”„ Creating spectrogram from synthetic data...\")\n",
    "                spectrogram_from_timeseries(demo_file, spectrogram_file, feature_extractor=feature_extractor)\n",
    "                \n",
    "                if os.path.exists(spectrogram_file):\n",
    "                    spec_size = os.path.getsize(spectrogram_file)\n",
    "                    print(f\"âœ… Created spectrogram: {spectrogram_file} ({spec_size:,} bytes)\")\n",
    "                    print(\"   ğŸ¯ Ready for audio classification training!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not create spectrogram: {e}\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âš ï¸ Transformers not available: {e}\")\n",
    "        print(\"   Install with: pip install transformers torch\")\n",
    "    \n",
    "    # Demo 4: Multiple Distortion Levels\n",
    "    print(f\"\\nğŸšï¸  Demo 4: Multiple Distortion Levels\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    distortion_levels = [\"none\", \"low\", \"high\"]\n",
    "    distortion_values = [0.0, 1.0, 2.5]\n",
    "    \n",
    "    print(\"ğŸ”„ Generating data for all distortion levels...\")\n",
    "    \n",
    "    for level, value in zip(distortion_levels, distortion_values):\n",
    "        try:\n",
    "            quick_plan = {\n",
    "                \"initialization\": {\n",
    "                    \"pose\": {\"origin\": {\"lat\": 38.446, \"lng\": -122.687, \"height\": 0.0}, \"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"rotation\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}},\n",
    "                    \"start_time_ns\": 0,\n",
    "                    \"sample_rate\": 30,\n",
    "                    \"mag\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[0.00053, 0.0, 0.0], [0.0, 0.00053, 0.0], [0.0, 0.0, 0.00053]]}},\n",
    "                    \"acc\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}},\n",
    "                    \"gyro\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}}\n",
    "                },\n",
    "                \"segments\": [{\n",
    "                    \"name\": f\"quick_{level}\",\n",
    "                    \"duration_s\": 5.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 45.0, \"pitch\": 0.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": value,\n",
    "                    \"mag_distortion\": {\"level\": level}\n",
    "                }]\n",
    "            }\n",
    "            \n",
    "            quick_file = f\"quick_{level}.mcap\"\n",
    "            generator.generate(plan_data=quick_plan, output_file=quick_file, verbose=False)\n",
    "            \n",
    "            if os.path.exists(quick_file):\n",
    "                # Read magnetometer data to see the effect\n",
    "                data = read_synthetic_sensor_data(quick_file, channels=[\"mag_truth\", \"mag_raw\"])\n",
    "                \n",
    "                if \"mag_truth\" in data and len(data[\"mag_truth\"]) > 0:\n",
    "                    mag_values = [item[1] for item in data[\"mag_truth\"][:100]]  # First 100 samples\n",
    "                    mag_magnitudes = [np.sqrt(sum(v**2 for v in vals)) for vals in mag_values]\n",
    "                    \n",
    "                    avg_magnitude = np.mean(mag_magnitudes)\n",
    "                    print(f\"   ğŸ§² {level:>4} distortion (value={value:>3.1f}): avg magnitude = {avg_magnitude:.3f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error with {level} level: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot run demos - required modules not available\")\n",
    "    print(\"Please check your environment setup\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Next Steps:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. ğŸ‹ï¸  Use fine_tune.ipynb to train a model with synthetic data\")\n",
    "print(\"2. ğŸ¯ Use classify.ipynb to test classification on new synthetic data\")\n",
    "print(\"3. ğŸ”§ Modify motion plans and distortion levels for custom scenarios\")\n",
    "print(\"4. ğŸ“Š Analyze the synthetic data to understand sensor behavior\")\n",
    "print(\"5. ğŸš€ Deploy trained models for real-world magnetic distortion detection\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Benefits of Synthetic Data:\")\n",
    "print(\"- ğŸ›ï¸  Full control over distortion levels and motion patterns\")\n",
    "print(\"- ğŸ“ˆ Unlimited training data generation\")\n",
    "print(\"- ğŸ§ª Perfect ground truth labels\")\n",
    "print(\"- ğŸ”„ Reproducible experiments\")\n",
    "print(\"- ğŸ’° No need for expensive real sensor data collection\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Synthetic data exploration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration and Capabilities\n",
    "\n",
    "This notebook demonstrates the capabilities of the time-series-classifier project's new modular architecture.\n",
    "\n",
    "## Features Demonstrated:\n",
    "\n",
    "### 1. **Synthetic Data Generation**\n",
    "- Uses the new `SyntheticDataGenerator` class\n",
    "- Reads and analyzes synthetic sensor data (magnetometer, accelerometer, gyroscope)\n",
    "- Shows how synthetic data integrates with the ML pipeline\n",
    "\n",
    "### 2. **Modular MCAP Utilities**\n",
    "- Demonstrates the new `mcap_utils` module structure\n",
    "- Shows window extraction for machine learning applications\n",
    "- Illustrates data reading and analysis capabilities\n",
    "\n",
    "### 3. **HuggingFace Integration**\n",
    "- Shows how the system integrates with transformers and datasets\n",
    "- Demonstrates the Audio Spectrogram Transformer (AST) model\n",
    "- Illustrates the complete ML pipeline\n",
    "\n",
    "### 4. **Improved Architecture**\n",
    "- Showcases the new modular imports\n",
    "- Demonstrates fallback capabilities for different environments\n",
    "- Shows integration between synthetic data and ML models\n",
    "\n",
    "## Key Improvements:\n",
    "- **Modular Design**: Clean separation of concerns across modules\n",
    "- **Better Error Handling**: Graceful fallbacks and clear error messages\n",
    "- **Synthetic Data Support**: First-class support for synthetic sensor data\n",
    "- **ML Pipeline Integration**: Seamless integration with HuggingFace ecosystem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
