{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Add src directory to path for modular imports\n",
    "script_dir = os.path.dirname(os.path.abspath(''))\n",
    "src_dir = os.path.abspath(os.path.join(script_dir, \"src\"))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "print(\"üî¨ Synthetic Data Explorer & Generator\")\n",
    "print(\"=====================================\")\n",
    "print(\"This notebook demonstrates the complete synthetic data pipeline\")\n",
    "print(\"for magnetic distortion classification.\\n\")\n",
    "\n",
    "# Try to use new modular imports\n",
    "try:\n",
    "    from mcap_utils import read_synthetic_sensor_data, plot_synthetic_sensor_data, extract_imu_windows\n",
    "    from synthetic import SyntheticDataGenerator\n",
    "    print(\"‚úÖ Modular architecture loaded successfully\")\n",
    "    modular_available = True\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Modular imports failed: {e}\")\n",
    "    print(\"Trying legacy imports...\")\n",
    "    try:\n",
    "        import mcap_utilities\n",
    "        from synthetic import SyntheticDataGenerator  # This should still work\n",
    "        read_synthetic_sensor_data = mcap_utilities.read_synthetic_sensor_data\n",
    "        plot_synthetic_sensor_data = mcap_utilities.plot_synthetic_sensor_data\n",
    "        extract_imu_windows = mcap_utilities.extract_imu_windows\n",
    "        print(\"‚úÖ Legacy imports successful\")\n",
    "        modular_available = False\n",
    "    except ImportError as e2:\n",
    "        print(f\"‚ùå All imports failed: {e2}\")\n",
    "        print(\"Please check your environment setup\")\n",
    "        modular_available = False\n",
    "\n",
    "if modular_available:\n",
    "    # Demo 1: Generate Synthetic Data Live\n",
    "    print(\"\\nüß™ Demo 1: Live Synthetic Data Generation\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    try:\n",
    "        generator = SyntheticDataGenerator()\n",
    "        print(\"‚úÖ SyntheticDataGenerator initialized\")\n",
    "        \n",
    "        # Create a simple demonstration plan\n",
    "        demo_plan = {\n",
    "            \"initialization\": {\n",
    "                \"pose\": {\n",
    "                    \"origin\": {\"lat\": 38.446, \"lng\": -122.687, \"height\": 0.0},\n",
    "                    \"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0},\n",
    "                    \"rotation\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}\n",
    "                },\n",
    "                \"start_time_ns\": 0,\n",
    "                \"sample_rate\": 50,  # Lower sample rate for demo\n",
    "                \"mag\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[0.00053, 0.0, 0.0], [0.0, 0.00053, 0.0], [0.0, 0.0, 0.00053]]}},\n",
    "                \"acc\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}},\n",
    "                \"gyro\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}}\n",
    "            },\n",
    "            \"segments\": [\n",
    "                {\n",
    "                    \"name\": \"demo_none\",\n",
    "                    \"duration_s\": 10.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 30.0, \"pitch\": 0.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": 0.0,\n",
    "                    \"mag_distortion\": {\"level\": \"none\"}\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"demo_high\",\n",
    "                    \"duration_s\": 10.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 0.0, \"pitch\": 30.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": 2.5,\n",
    "                    \"mag_distortion\": {\"level\": \"high\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Generate demo data\n",
    "        demo_file = \"demo_synthetic_data.mcap\"\n",
    "        demo_labels = \"demo_synthetic_data.labels.json\"\n",
    "        \n",
    "        print(\"\udd04 Generating 20 seconds of demo data...\")\n",
    "        generator.generate(plan_data=demo_plan, output_file=demo_file, verbose=False)\n",
    "        generator.generate_labels(demo_plan, demo_labels)\n",
    "        \n",
    "        if os.path.exists(demo_file):\n",
    "            file_size = os.path.getsize(demo_file)\n",
    "            print(f\"‚úÖ Generated {demo_file} ({file_size:,} bytes)\")\n",
    "            \n",
    "            # Read and analyze the generated data\n",
    "            print(\"\\nüìä Analyzing Generated Data...\")\n",
    "            data = read_synthetic_sensor_data(demo_file)\n",
    "            \n",
    "            print(f\"üìã Available channels ({len(data)}):\")\n",
    "            for channel, channel_data in data.items():\n",
    "                if len(channel_data) > 0:\n",
    "                    timestamps = [item[0] for item in channel_data[:5]]  # First 5 timestamps\n",
    "                    print(f\"  üìà {channel}: {len(channel_data)} samples\")\n",
    "                    if len(channel_data) > 0:\n",
    "                        sample_timestamp, sample_values = channel_data[0]\n",
    "                        print(f\"      Sample: t={sample_timestamp/1e9:.3f}s, values={sample_values}\")\n",
    "            \n",
    "            # Analyze labels\n",
    "            print(f\"\\nüè∑Ô∏è  Analyzing Labels...\")\n",
    "            with open(demo_labels, 'r') as f:\n",
    "                labels_data = json.load(f)\n",
    "                events = labels_data.get('events', [])\n",
    "                print(f\"üìã Found {len(events)} labeled events:\")\n",
    "                for i, event in enumerate(events):\n",
    "                    name = event.get('metadata', {}).get('mag_distortion', 'unknown')\n",
    "                    start_time = event['startTime']['sec']\n",
    "                    end_time = event['endTime']['sec']\n",
    "                    duration = end_time - start_time\n",
    "                    print(f\"  {i+1}. {name} distortion: {start_time}s - {end_time}s ({duration}s)\")\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ùå Failed to generate demo data\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in synthetic data generation: {e}\")\n",
    "    \n",
    "    # Demo 2: Data Analysis and Visualization\n",
    "    print(f\"\\nüìä Demo 2: Data Analysis & Visualization\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    if 'demo_file' in locals() and os.path.exists(demo_file):\n",
    "        try:\n",
    "            # Extract windows for ML\n",
    "            print(\"üîÑ Extracting windows for machine learning...\")\n",
    "            windows = extract_imu_windows(demo_file, window_size_ns=2e9, channels=['mag_truth', 'acc_truth', 'gyro_truth'])\n",
    "            \n",
    "            if len(windows) > 0:\n",
    "                print(f\"‚úÖ Extracted {len(windows)} windows\")\n",
    "                print(f\"   Window shape: {windows[0].shape}\")\n",
    "                print(f\"   Data type: {windows[0].dtype}\")\n",
    "                \n",
    "                # Show some statistics\n",
    "                print(f\"\\nüìà Window Statistics:\")\n",
    "                all_data = np.concatenate(windows, axis=0)\n",
    "                print(f\"   Combined shape: {all_data.shape}\")\n",
    "                print(f\"   Data range: [{np.min(all_data):.3f}, {np.max(all_data):.3f}]\")\n",
    "                print(f\"   Mean: {np.mean(all_data):.3f}\")\n",
    "                print(f\"   Std: {np.std(all_data):.3f}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No windows extracted\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not extract windows: {e}\")\n",
    "    \n",
    "    # Demo 3: Integration with ML Pipeline\n",
    "    print(f\"\\nü§ñ Demo 3: Machine Learning Integration\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    try:\n",
    "        from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "        \n",
    "        # Load a pretrained model for demonstration\n",
    "        print(\"üîÑ Loading pretrained Audio Spectrogram Transformer...\")\n",
    "        feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        \n",
    "        print(\"‚úÖ Loaded pretrained AST model\")\n",
    "        print(f\"   üìä Model classes: {model.config.num_labels}\")\n",
    "        print(f\"   üè∑Ô∏è  Sample classes: {list(model.config.id2label.values())[:5]}...\")\n",
    "        \n",
    "        # Show how to create spectrograms\n",
    "        if 'demo_file' in locals() and os.path.exists(demo_file):\n",
    "            try:\n",
    "                from mcap_utils import spectrogram_from_timeseries\n",
    "                spectrogram_file = \"demo_synthetic_data.spectrogram.mcap\"\n",
    "                \n",
    "                print(f\"üîÑ Creating spectrogram from synthetic data...\")\n",
    "                spectrogram_from_timeseries(demo_file, spectrogram_file, feature_extractor=feature_extractor)\n",
    "                \n",
    "                if os.path.exists(spectrogram_file):\n",
    "                    spec_size = os.path.getsize(spectrogram_file)\n",
    "                    print(f\"‚úÖ Created spectrogram: {spectrogram_file} ({spec_size:,} bytes)\")\n",
    "                    print(\"   üéØ Ready for audio classification training!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not create spectrogram: {e}\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ö†Ô∏è Transformers not available: {e}\")\n",
    "        print(\"   Install with: pip install transformers torch\")\n",
    "    \n",
    "    # Demo 4: Multiple Distortion Levels\n",
    "    print(f\"\\nüéöÔ∏è  Demo 4: Multiple Distortion Levels\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    distortion_levels = [\"none\", \"low\", \"high\"]\n",
    "    distortion_values = [0.0, 1.0, 2.5]\n",
    "    \n",
    "    print(\"üîÑ Generating data for all distortion levels...\")\n",
    "    \n",
    "    for level, value in zip(distortion_levels, distortion_values):\n",
    "        try:\n",
    "            quick_plan = {\n",
    "                \"initialization\": {\n",
    "                    \"pose\": {\"origin\": {\"lat\": 38.446, \"lng\": -122.687, \"height\": 0.0}, \"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"rotation\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}},\n",
    "                    \"start_time_ns\": 0,\n",
    "                    \"sample_rate\": 30,\n",
    "                    \"mag\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[0.00053, 0.0, 0.0], [0.0, 0.00053, 0.0], [0.0, 0.0, 0.00053]]}},\n",
    "                    \"acc\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}},\n",
    "                    \"gyro\": {\"calibration\": {\"bias\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"matrix\": [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]}}\n",
    "                },\n",
    "                \"segments\": [{\n",
    "                    \"name\": f\"quick_{level}\",\n",
    "                    \"duration_s\": 5.0,\n",
    "                    \"rotation_rpy_degrees\": {\"roll\": 45.0, \"pitch\": 0.0, \"yaw\": 0.0},\n",
    "                    \"magnetic_distortion\": value,\n",
    "                    \"mag_distortion\": {\"level\": level}\n",
    "                }]\n",
    "            }\n",
    "            \n",
    "            quick_file = f\"quick_{level}.mcap\"\n",
    "            generator.generate(plan_data=quick_plan, output_file=quick_file, verbose=False)\n",
    "            \n",
    "            if os.path.exists(quick_file):\n",
    "                # Read magnetometer data to see the effect\n",
    "                data = read_synthetic_sensor_data(quick_file, channels=[\"mag_truth\", \"mag_raw\"])\n",
    "                \n",
    "                if \"mag_truth\" in data and len(data[\"mag_truth\"]) > 0:\n",
    "                    mag_values = [item[1] for item in data[\"mag_truth\"][:100]]  # First 100 samples\n",
    "                    mag_magnitudes = [np.sqrt(sum(v**2 for v in vals)) for vals in mag_values]\n",
    "                    \n",
    "                    avg_magnitude = np.mean(mag_magnitudes)\n",
    "                    print(f\"   üß≤ {level:>4} distortion (value={value:>3.1f}): avg magnitude = {avg_magnitude:.3f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error with {level} level: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot run demos - required modules not available\")\n",
    "    print(\"Please check your environment setup\")\n",
    "\n",
    "print(f\"\\nüéØ Next Steps:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. üèãÔ∏è  Use fine_tune.ipynb to train a model with synthetic data\")\n",
    "print(\"2. üéØ Use classify.ipynb to test classification on new synthetic data\")\n",
    "print(\"3. üîß Modify motion plans and distortion levels for custom scenarios\")\n",
    "print(\"4. üìä Analyze the synthetic data to understand sensor behavior\")\n",
    "print(\"5. üöÄ Deploy trained models for real-world magnetic distortion detection\")\n",
    "\n",
    "print(f\"\\nüí° Key Benefits of Synthetic Data:\")\n",
    "print(\"- üéõÔ∏è  Full control over distortion levels and motion patterns\")\n",
    "print(\"- üìà Unlimited training data generation\")\n",
    "print(\"- üß™ Perfect ground truth labels\")\n",
    "print(\"- üîÑ Reproducible experiments\")\n",
    "print(\"- üí∞ No need for expensive real sensor data collection\")\n",
    "\n",
    "print(f\"\\nüéâ Synthetic data exploration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration and Capabilities\n",
    "\n",
    "This notebook demonstrates the capabilities of the time-series-classifier project's new modular architecture.\n",
    "\n",
    "## Features Demonstrated:\n",
    "\n",
    "### 1. **Synthetic Data Generation**\n",
    "- Uses the new `SyntheticDataGenerator` class\n",
    "- Reads and analyzes synthetic sensor data (magnetometer, accelerometer, gyroscope)\n",
    "- Shows how synthetic data integrates with the ML pipeline\n",
    "\n",
    "### 2. **Modular MCAP Utilities**\n",
    "- Demonstrates the new `mcap_utils` module structure\n",
    "- Shows window extraction for machine learning applications\n",
    "- Illustrates data reading and analysis capabilities\n",
    "\n",
    "### 3. **HuggingFace Integration**\n",
    "- Shows how the system integrates with transformers and datasets\n",
    "- Demonstrates the Audio Spectrogram Transformer (AST) model\n",
    "- Illustrates the complete ML pipeline\n",
    "\n",
    "### 4. **Improved Architecture**\n",
    "- Showcases the new modular imports\n",
    "- Demonstrates fallback capabilities for different environments\n",
    "- Shows integration between synthetic data and ML models\n",
    "\n",
    "## Key Improvements:\n",
    "- **Modular Design**: Clean separation of concerns across modules\n",
    "- **Better Error Handling**: Graceful fallbacks and clear error messages\n",
    "- **Synthetic Data Support**: First-class support for synthetic sensor data\n",
    "- **ML Pipeline Integration**: Seamless integration with HuggingFace ecosystem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
